{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CuBGJnN3UOc"
   },
   "source": [
    "## Question-1: Smart Greeting Function for a GenAI App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1767360641484,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "iqovmPUV22B9",
    "outputId": "7ecf0be4-16e0-460b-beb2-d76a90e62e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Chandu! Welcome to GenAI.\n",
      "Hello, akhila! Welcome to GenAI.\n",
      "Hello, Welcome to GenAI.\n"
     ]
    }
   ],
   "source": [
    "def generate_greeting(name):\n",
    "  if name==\" \":\n",
    "    print(f\"Hello, Welcome to GenAI.\")\n",
    "  else:\n",
    "    print(f\"Hello, {name.strip()}! Welcome to GenAI.\")\n",
    "\n",
    "generate_greeting(\"Chandu\")\n",
    "generate_greeting(\" akhila \")\n",
    "generate_greeting(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiqpPrOx6AY1"
   },
   "source": [
    "## Question-2: Function That Prints a Mini Report (Define + Call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1767361134459,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "YxgV7Mn24XYz",
    "outputId": "32ab1b1e-f60d-473e-e6bb-af2e57597307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model : gpt\n",
      "Tokens Used : 120\n",
      "Cost Per Token : 0.02\n",
      "Total Cost : 2.4\n",
      "Model : gpt\n",
      "Tokens Used : 120\n",
      "Cost Per Token : 0.02\n",
      "Total Cost : 2.4\n"
     ]
    }
   ],
   "source": [
    "def daily_genai_report():\n",
    "  model_name = \"gpt\"\n",
    "  tokens_used = 120\n",
    "  cost_per_token = 0.02\n",
    "\n",
    "  total_cost = tokens_used * cost_per_token\n",
    "\n",
    "  print(f\"Model : {model_name}\")\n",
    "  print(f\"Tokens Used : {tokens_used}\")\n",
    "  print(f\"Cost Per Token : {cost_per_token}\")\n",
    "  print(f\"Total Cost : {total_cost}\")\n",
    "\n",
    "daily_genai_report()\n",
    "daily_genai_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCdsgGVL77SX"
   },
   "source": [
    "## Question-3: Positional Arguments and Order Matters (Compute AI Credits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1767361891878,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "RyV7B2sn6jFH",
    "outputId": "589c2f32-4111-4d22-c50d-b62fbf017751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Chandu\n",
      "\n",
      "Credits Purchased: 50\n",
      "Price Per Credit: 3\n",
      "Final Amount: 150\n",
      "\n",
      "User: Akhila\n",
      "\n",
      "Credits Purchased: 120\n",
      "Price Per Credit: 2\n",
      "Final Amount: 240\n",
      "\n",
      "User: Chandu\n",
      "\n",
      "Credits Purchased: 3\n",
      "Price Per Credit: 50\n",
      "Final Amount: 150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def buy_credits(user_name, credits, price_per_credit):\n",
    "\n",
    "  final_amount = credits * price_per_credit\n",
    "  print(f\"User: {user_name}\\n\")\n",
    "  print(f\"Credits Purchased: {credits}\")\n",
    "  print(f\"Price Per Credit: {price_per_credit}\")\n",
    "  print(f\"Final Amount: {final_amount}\\n\")\n",
    "\n",
    "buy_credits(\"Chandu\", 50, 3)\n",
    "buy_credits(\"Akhila\", 120, 2)\n",
    "buy_credits(\"Chandu\", 3, 50)\n",
    "# The buy_credits(\"Chandu\", 3, 50) is wrong because the position of credits and price_per_credit is interchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZU2U6TZ5_hkr"
   },
   "source": [
    "## Question-4: return vs print — Build a Reusable Discount System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1767363645067,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "uLq0qc2Q9HSW",
    "outputId": "08b685c0-5555-4a31-f204-f784f5aa7985"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final_Price=90.0\n",
      "None\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "def discount_print(price, discount_percent):\n",
    "  Discounted_Price=price-price*discount_percent/100\n",
    "  print(f\"Final_Price={Discounted_Price}\")\n",
    "\n",
    "def discount_return(price, discount_percent):\n",
    "  Discounted_Price=price-price*discount_percent/100\n",
    "  return price-price*discount_percent/100\n",
    "\n",
    "a=discount_print(100,10)  # It is returning \"Final_Price=90.0\"\n",
    "b=discount_return(100,10) # It is returning \"90.0\" because we have returned the value therefore it is stored internally\n",
    "print(a)                  # It is returning \"None\" because we have not returned the value from the function it is not stored internally it is just displayed on the console\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61wRikrGFV5X"
   },
   "source": [
    "## Question-5: Lambda Tasks for Prompt Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1767372423285,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "7cAo7PZvFVhS",
    "outputId": "3455ab45-9397-4249-85f6-20d73f194576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 9, 13, 2, 10, 2]\n",
      "['Write a poem', 'Summarize', 'Generate code', 'Explain AI']\n"
     ]
    }
   ],
   "source": [
    "prompts = [\"Write a poem\", \"Summarize\", \"Generate code\", \"Hi\", \"Explain AI\", \"Ok\"]\n",
    "\n",
    "list1= map(lambda x:len(x),prompts)\n",
    "list2=filter(lambda x:len(x)>5,prompts)\n",
    "\n",
    "print(list(list1))\n",
    "print(list(list2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efOINwbIm4pK"
   },
   "source": [
    "## Question-6: Text File Handling — Save and Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 110,
     "status": "ok",
     "timestamp": 1767374790033,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "rqGeRhsEBgw2",
    "outputId": "a87f8b3c-57e5-4070-e8b0-819d4a64b6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=gpt\n",
      "temperature=0.7\n",
      "max_tokens=200\n",
      "\n",
      "Verifying before closing:False\n",
      "Verifying after closing:True\n"
     ]
    }
   ],
   "source": [
    "f = open(\"config.txt\", \"w\")\n",
    "f.write('''model=gpt\n",
    "temperature=0.7\n",
    "max_tokens=200\\n''')\n",
    "f.close()\n",
    "\n",
    "f = open(\"config.txt\", \"r\")\n",
    "print(f.read())\n",
    "print(f\"Verifying before closing:{f.closed}\")\n",
    "f.close()\n",
    "print(f\"Verifying after closing:{f.closed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tKaPo5Iv1H_"
   },
   "source": [
    "## Question-7: CSV File Handling — Filter Logs by Token Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1767377695119,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "1AKnAtoIpO-V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-06-08 10:08:00', 'Code review', '156', '4.5']\n",
      "['2023-06-08 10:10:00', 'Data analysis', '234', '5.8']\n",
      "High Token Requests: 2\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"model_logs.csv\",\"r\") as file:\n",
    "  reader_object=csv.reader(file)         # Used csv.reader to read the file\n",
    "\n",
    "  next(reader_object)                    # For skipping the first row\n",
    "\n",
    "  count=0\n",
    "  for row in reader_object:\n",
    "    Tokens=int(row[2])                   # Converting Tokens string to integer\n",
    "    if Tokens > 100:\n",
    "      print(row)\n",
    "      count+=1                           # Counting the number of rows\n",
    "print(f\"High Token Requests: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m-ukwFnEovz"
   },
   "source": [
    "## Question-8: Modules — Build a Prompt Utility Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVgGziDhy2ug"
   },
   "outputs": [],
   "source": [
    "# # File-1: prompt_utils.py\n",
    "\n",
    "# def clean_text(text):\n",
    "#     cleaned_text=text.strip().lower()\n",
    "#     return cleaned_text\n",
    "\n",
    "# def is_long_prompt(text):\n",
    "#     return len(text)>20\n",
    "\n",
    "# # File-2: main.py\n",
    "# from prompt_utils import clean_text, is_long_prompt\n",
    "\n",
    "# cleaned_text=clean_text(\" Write a detailed blog on Generative AI in simple words \")\n",
    "# is_long_prompt(\" Write a detailed blog on Generative AI in simple words \")\n",
    "\n",
    "# print(cleaned_text)\n",
    "# print(is_long_prompt(cleaned_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OVSeVu4KSj0"
   },
   "source": [
    "## Question-9: Exception Handling — Safe Calculator for GenAI Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7520,
     "status": "ok",
     "timestamp": 1767382450487,
     "user": {
      "displayName": "Dheeraj Chavhan",
      "userId": "17665749559651527326"
     },
     "user_tz": -330
    },
    "id": "hZ8XMUktKUSb",
    "outputId": "9da12582-b7d9-4202-99bc-b8a7c94bdfe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tokens Per Request: 1.3235294117647058\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  total_tokens=int(input(\"Enter no.of tokens: \"))\n",
    "  num_requests=int(input(\"Enter no.of requests: \"))\n",
    "  avg_tokens = total_tokens / num_requests\n",
    "  print(f\"Average Tokens Per Request: {avg_tokens}\")\n",
    "\n",
    "except ValueError:\n",
    "  print(\"Error! , Enter the Integer value\")\n",
    "\n",
    "except ZeroDivisionError:\n",
    "  print(\"Error! , No. of requests must be more than Zero\")\n",
    "\n",
    "except Exception as e:\n",
    "  print(\"Error:\",e)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPM0F3dt+TtOYVRvT9tK7j7",
   "collapsed_sections": [
    "_CuBGJnN3UOc",
    "KiqpPrOx6AY1",
    "rCdsgGVL77SX",
    "ZU2U6TZ5_hkr",
    "61wRikrGFV5X",
    "efOINwbIm4pK",
    "9tKaPo5Iv1H_",
    "5m-ukwFnEovz",
    "5OVSeVu4KSj0"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
